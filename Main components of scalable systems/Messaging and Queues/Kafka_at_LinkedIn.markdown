# نمونه واقعی: استفاده از Apache Kafka در LinkedIn برای پردازش داده‌ها

این سند به بررسی استفاده از **Apache Kafka** در شرکت LinkedIn به‌عنوان یک سیستم جریان داده و پیام‌رسانی مقیاس‌پذیر می‌پردازد. هدف این است که با ارائه جزئیات در مورد نیازهای LinkedIn، مشکلات پیش از Kafka، چگونگی توسعه Kafka، معماری و کاربردهای آن، مزایا، درس‌های آموخته‌شده و تأثیرات آن بر سیستم‌های مدرن مبتنی بر رویداد، یک راهنمای جامع و آموزشی برای یادگیری طراحی سیستم فراهم شود. این محتوا به زبان فارسی و با فرمت مارک‌داون ارائه شده است تا برای مستندسازی آموزشی و یادگیری اصول طراحی سیستم مناسب باشد.

---

## مقدمه: چرا LinkedIn به یک سیستم قدرتمند جریان داده و پیام‌رسانی نیاز داشت؟

LinkedIn، به‌عنوان یکی از بزرگ‌ترین پلتفرم‌های شبکه‌های اجتماعی حرفه‌ای با بیش از 675 میلیون کاربر در سال 2020، روزانه با حجم عظیمی از داده‌ها و تعاملات کاربران مواجه است. این تعاملات شامل فعالیت‌های کاربران (مانند بازدید از صفحات، جستجو، ارسال پیام)، معیارهای عملیاتی (مانند مصرف CPU و حافظه سرورها)، و لاگ‌های سیستم است. برای مدیریت این حجم عظیم داده و ارائه تجربه کاربری بلادرنگ و قابل‌اعتماد، LinkedIn به یک سیستم جریان داده و پیام‌رسانی نیاز داشت که بتواند:

- **حجم بالای داده‌ها را مدیریت کند:** پردازش میلیاردها پیام در روز با توان عملیاتی بالا.
- **تأخیر کم ارائه دهد:** پاسخگویی بلادرنگ برای ویژگی‌هایی مانند اعلان‌ها و به‌روزرسانی فیدها.
- **مقیاس‌پذیر و مقاوم باشد:** پشتیبانی از رشد سریع کاربران و پایداری در برابر خرابی‌ها.
- **سرویس‌ها را جدا کند:** امکان ارتباط ناهمزمان بین سرویس‌های مختلف بدون وابستگی مستقیم.

**Apache Kafka**، که در ابتدا توسط LinkedIn توسعه یافت، به‌عنوان راه‌حل این نیازها طراحی شد و به یکی از ستون‌های اصلی زیرساخت داده این شرکت تبدیل شد.[](https://softwareengineeringdaily.com/2020/02/20/linkedin-kafka/)[](https://www.linkedin.com/pulse/kafkas-origin-story-linkedin-tanvir-ahmed)

---

## پیش‌زمینه: مشکلات LinkedIn در مقیاس‌پذیری و خطوط لوله داده قبل از Kafka

قبل از توسعه Kafka در سال 2010، LinkedIn با چالش‌های متعددی در مدیریت داده‌های خود مواجه بود:

- **حجم عظیم داده‌ها:** با رشد سریع تعداد کاربران، داده‌های فعالیت کاربران (مانند کلیک‌ها، بازدیدها، و جستجوها) و معیارهای عملیاتی به‌صورت تصاعدی افزایش یافت.
- **محدودیت‌های سیستم‌های پیام‌رسانی سنتی:** سیستم‌هایی مانند ActiveMQ و RabbitMQ برای مدیریت حجم بالای داده‌ها و ارائه تأخیر کم ناکافی بودند. این سیستم‌ها معمولاً با افزایش تعداد مصرف‌کنندگان کند می‌شدند و مقیاس‌پذیری محدودی داشتند.[](https://www.linkedin.com/pulse/linkedin-apache-kafka-muhammad-waqas-dilawar)[](https://www.linkedin.com/pulse/kafkas-origin-story-linkedin-tanvir-ahmed)
- **پیچیدگی خطوط لوله داده:** LinkedIn از ده‌ها سیستم داده و مخزن داده (مانند پایگاه‌های داده و Hadoop) استفاده می‌کرد. اتصال این سیستم‌ها نیاز به خطوط لوله سفارشی بین هر جفت سیستم داشت، که منجر به پیچیدگی و هزینه‌های نگهداری بالا می‌شد.
- **نیاز به پردازش بلادرنگ و دسته‌ای:** LinkedIn به سیستمی نیاز داشت که هم برای پردازش بلادرنگ (مانند اعلان‌ها) و هم برای تحلیل‌های دسته‌ای (مانند گزارش‌های Hadoop) مناسب باشد.
- **عدم انعطاف‌پذیری:** سیستم‌های موجود نمی‌توانستند به‌خوبی مصرف‌کنندگان و تولیدکنندگان را از یکدیگر جدا کنند، که باعث کاهش عملکرد و افزایش وابستگی‌ها می‌شد.

این چالش‌ها LinkedIn را وادار کرد تا یک سیستم پیام‌رسانی جدید طراحی کند که مقیاس‌پذیر، با تأخیر کم، و مقاوم باشد.

---

## منشأ Kafka در LinkedIn: چگونگی و چرایی توسعه

**Apache Kafka** در حدود سال 2010 توسط تیمی در LinkedIn شامل Jay Kreps، Jun Rao و Neha Narkhede توسعه یافت. هدف اصلی، حل مشکل **جذب داده‌های با تأخیر کم** در حجم بالا برای پشتیبانی از معماری لامبدا (ترکیب پردازش بلادرنگ و دسته‌ای) بود.[](https://www.linkedin.com/pulse/kafkas-origin-story-linkedin-tanvir-ahmed)

### چرا Kafka توسعه یافت؟
- **نیاز به مقیاس‌پذیری افقی:** سیستم‌های پیام‌رسانی سنتی نمی‌توانستند با رشد داده‌های LinkedIn مقیاس‌پذیر شوند.
- **پشتیبانی از پردازش بلادرنگ:** برخلاف سیستم‌های دسته‌ای، LinkedIn به سیستمی نیاز داشت که بتواند داده‌ها را با تأخیر کم (در حد میلی‌ثانیه) پردازش کند.
- **جداسازی تولیدکنندگان و مصرف‌کنندگان:** برای کاهش وابستگی‌ها و افزایش انعطاف‌پذیری، نیاز به یک لایه واسطه بود که داده‌ها را به‌صورت ناهمزمان منتقل کند.
- **پشتیبانی از ذخیره‌سازی داده‌ها:** برخلاف پیام‌رسان‌های سنتی که پیام‌ها را پس از مصرف حذف می‌کنند، LinkedIn به سیستمی نیاز داشت که داده‌ها را برای بازپخش و تحلیل‌های بعدی ذخیره کند.

### چگونگی توسعه
Kafka به‌عنوان یک **سیستم پیام‌رسانی مبتنی بر لاگ توزیع‌شده** طراحی شد که از مدل **انتشار/اشتراک (Publish/Subscribe)** استفاده می‌کند. ویژگی‌های کلیدی آن شامل:
- **موضوعات (Topics):** داده‌ها در دسته‌های منطقی به نام موضوعات ذخیره می‌شوند.
- **پارتیشن‌ها:** هر موضوع به پارتیشن‌های متعدد تقسیم می‌شود تا پردازش موازی و مقیاس‌پذیری فراهم شود.
- **لاگ‌های پایدار:** پیام‌ها به‌صورت لاگ روی دیسک ذخیره می‌شوند، که امکان بازپخش و پایداری را فراهم می‌کند.
- **کارگزاران (Brokers):** سرورهای Kafka که داده‌ها را ذخیره و مدیریت می‌کنند.

Kafka در سال 2011 به Apache Software Foundation اهدا شد و به یک پروژه متن‌باز تبدیل شد، که اکنون توسط شرکت‌های بزرگی مانند Netflix و Uber استفاده می‌شود.[](https://en.wikipedia.org/wiki/Apache_Kafka)[](https://www.rtinsights.com/the-technical-evolution-of-apache-kafka-from-linkedins-need-to-a-global-standard/)

---

## معماری و کاربردهای کلیدی Kafka در LinkedIn

LinkedIn از Kafka به‌عنوان ستون فقرات زیرساخت داده خود استفاده می‌کند و بیش از **7 تریلیون پیام در روز** را با بیش از **100 خوشه Kafka**، **4000 کارگزار**، **100,000 موضوع** و **7 میلیون پارتیشن** پردازش می‌کند. در ادامه، جزئیات معماری و کاربردهای Kafka در LinkedIn بررسی می‌شود.[](https://blog.bytebytego.com/p/how-linkedin-customizes-its-7-trillion)[](https://www.linkedin.com/blog/engineering/open-source/apache-kafka-trillion-messages)

### جریان‌های رویداد (Event Streams)
Kafka برای مدیریت انواع مختلف جریان‌های رویداد در LinkedIn استفاده می‌شود:
- **فعالیت‌های کاربران:** شامل کلیک‌ها، بازدیدهای صفحه، جستجوها، لایک‌ها، اشتراک‌گذاری‌ها و نظرات. این داده‌ها برای به‌روزرسانی فیدهای خبری، توصیه‌ها و تبلیغات هدفمند استفاده می‌شوند.
- **پیام‌رسانی:** پیام‌های ارسالی بین کاربران (مانند InMail) از طریق Kafka منتقل می‌شوند.
- **معیارهای عملیاتی:** شامل معیارهای سیستم مانند مصرف CPU، حافظه، و تأخیر سرویس‌ها برای مانیتورینگ بلادرنگ.
- **لاگ‌ها:** لاگ‌های برنامه‌ها برای تجمیع و تحلیل به Kafka ارسال می‌شوند.

### ادغام با سایر سیستم‌ها
Kafka به‌عنوان یک **خط لوله داده یکپارچه** عمل می‌کند و با سیستم‌های مختلف ادغام می‌شود:
- **Apache Hadoop:** برای پردازش دسته‌ای داده‌ها، Kafka داده‌ها را به HDFS منتقل می‌کند. ابزار **Gobblin**، توسعه‌یافته توسط LinkedIn، داده‌ها را از Kafka به Hadoop منتقل می‌کند.[](https://softwareengineeringdaily.com/2020/02/20/linkedin-kafka/)
- **Apache Samza:** برای پردازش جریان‌های بلادرنگ، LinkedIn از Samza (که خود توسط LinkedIn توسعه یافته و به Apache اهدا شده) استفاده می‌کند. Samza وظایف سنگین مانند تحلیل بلادرنگ را از Hadoop به جریان‌های Kafka منتقل می‌کند.[](https://softwareengineeringdaily.com/2020/02/20/linkedin-kafka/)
- **Brooklin:** یک سرویس جریان توزیع‌شده که داده‌ها را از منابع مختلف (مانند پایگاه‌های داده یا ابرهای عمومی) به Kafka منتقل کرده و جریان‌هایی برای سایر برنامه‌ها تولید می‌کند.[](https://softwareengineeringdaily.com/2020/02/20/linkedin-kafka/)
- **دیتابیس‌ها و انبارهای داده:** Kafka برای تکثیر پایگاه داده (Database Replication) و انتقال داده‌ها به سیستم‌های تحلیلی استفاده می‌شود.

### مقیاس‌پذیری و توان عملیاتی بالا
- **مقیاس‌پذیری افقی:** LinkedIn از خوشه‌های Kafka با هزاران کارگزار استفاده می‌کند که امکان پردازش بیش از 7 تریلیون پیام در روز را فراهم می‌کند.
- **پارتیشن‌بندی:** هر موضوع به پارتیشن‌های متعدد تقسیم می‌شود که پردازش موازی توسط مصرف‌کنندگان را ممکن می‌سازد.
- **مدیریت خوشه‌ها:** ابزار **Cruise Control**، توسعه‌یافته توسط LinkedIn، برای مدیریت خودکار خوشه‌های Kafka و تعادل بار استفاده می‌شود.[](https://engineering.linkedin.com/teams/data/data-infrastructure/streams/kafka)
- **تأخیر کم:** Kafka تأخیرهایی در حد 2 میلی‌ثانیه ارائه می‌دهد، که برای برنامه‌های بلادرنگ حیاتی است.[](https://kafka.apache.org/)

### قابلیت اطمینان و تحمل‌پذیری خطا
- **پایداری داده‌ها:** پیام‌ها در لاگ‌های append-only روی دیسک ذخیره می‌شوند، که از حذف تصادفی جلوگیری می‌کند.
- **تکثیر (Replication):** LinkedIn از حداقل فاکتور تکثیر برای کاهش خطر از دست رفتن داده‌ها در صورت خرابی کارگزار استفاده می‌کند.[](https://www.linkedin.com/blog/engineering/open-source/apache-kafka-trillion-messages)
- **MirrorMaker:** برای تکثیر داده‌ها بین مراکز داده و حفظ سازگاری در چندین منطقه جغرافیایی استفاده می‌شود.[](http://insideainews.com/2016/04/28/a-brief-history-of-kafka-linkedins-messaging-platform/)
- **تحمل‌پذیری خطا:** پارتیشن‌بندی و تکثیر داده‌ها امکان ادامه کار سیستم در صورت خرابی کارگزارها را فراهم می‌کند.

---

## مزایای به‌دست‌آمده توسط LinkedIn با استفاده از Kafka

LinkedIn با پیاده‌سازی Kafka به مزایای زیر دست یافت:
- **مقیاس‌پذیری بی‌نظیر:** توانایی پردازش بیش از 7 تریلیون پیام در روز، که با رشد کاربران افزایش یافت.[](https://www.linkedin.com/blog/engineering/open-source/apache-kafka-trillion-messages)
- **پاسخگویی بلادرنگ:** ارائه تجربه کاربری بهبودیافته با به‌روزرسانی‌های فوری فیدها و اعلان‌ها.
- **جداسازی سرویس‌ها:** تولیدکنندگان و مصرف‌کنندگان از طریق Kafka جدا شدند، که توسعه و نگهداری سرویس‌ها را ساده کرد.
- **یکپارچگی داده‌ها:** Kafka به‌عنوان یک خط لوله مرکزی، نیاز به خطوط لوله سفارشی بین سیستم‌ها را حذف کرد.
- **پشتیبانی از معماری لامبدا:** ترکیب پردازش بلادرنگ (با Samza) و دسته‌ای (با Hadoop) برای تحلیل‌های جامع.
- **تأثیر در جامعه متن‌باز:** با اهدای Kafka به Apache، LinkedIn به توسعه سیستم‌های جریان داده در سطح جهانی کمک کرد.

---

## درس‌های آموخته‌شده و تأثیر بر سیستم‌های مدرن مبتنی بر رویداد

### درس‌های آموخته‌شده
1. **نیاز به مقیاس‌پذیری از ابتدا:** LinkedIn دریافت که سیستم‌های پیام‌رسانی سنتی نمی‌توانند با رشد سریع داده‌ها همگام شوند، بنابراین Kafka را با تمرکز بر مقیاس‌پذیری افقی طراحی کرد.
2. **اهمیت پایداری داده‌ها:** ذخیره‌سازی لاگ‌های پایدار امکان بازپخش داده‌ها و بازیابی در برابر خرابی‌ها را فراهم کرد.
3. **مدیریت پیچیدگی خوشه‌ها:** ابزارهایی مانند Cruise Control برای مدیریت خودکار خوشه‌های بزرگ ضروری هستند.
4. **ادغام با اکوسیستم داده:** Kafka به‌عنوان یک لایه واسطه، ادغام با سیستم‌های مختلف (مانند Hadoop و Samza) را ساده کرد.
5. **مشارکت در جامعه متن‌باز:** اهدای Kafka به Apache و انتشار شاخه‌های LinkedIn (مانند شاخه‌های -li) به توسعه‌دهندگان جهانی کمک کرد.[](https://www.linkedin.com/blog/engineering/open-source/apache-kafka-trillion-messages)

### تأثیر بر سیستم‌های مدرن
- **استانداردسازی جریان داده:** Kafka به استانداردی برای پردازش جریان داده در شرکت‌هایی مانند Netflix، Uber و Amazon تبدیل شد.
- **معماری‌های کاپا و لامبدا:** Kafka امکان پیاده‌سازی معماری‌های ترکیبی را فراهم کرد که پردازش بلادرنگ و دسته‌ای را ترکیب می‌کنند.[](https://www.linkedin.com/pulse/kafkas-origin-story-linkedin-tanvir-ahmed)
- **اکوسیستم قدرتمند:** ابزارهایی مانند Kafka Streams، Kafka Connect و Samza از Kafka الهام گرفته و توسعه یافتند.
- **پشتیبانی از میکروسرویس‌ها:** Kafka به‌عنوان یک ستون فقرات برای ارتباط ناهمزمان در معماری‌های میکروسرویس استفاده می‌شود.

---

## خلاصه و نکات کلیدی برای مهندسان طراحی سیستم

### خلاصه
- **نیاز LinkedIn:** مدیریت حجم عظیم داده‌های کاربران و معیارهای عملیاتی با تأخیر کم و مقیاس‌پذیری بالا.
- **توسعه Kafka:** Kafka در سال 2010 برای حل مشکلات سیستم‌های پیام‌رسانی سنتی طراحی شد و در سال 2011 متن‌باز شد.
- **کاربردها:** استفاده برای جریان‌های رویداد (فعالیت کاربران، پیام‌رسانی، معیارها)، ادغام با Hadoop و Samza، و پردازش بیش از 7 تریلیون پیام در روز.
- **مزایا:** مقیاس‌پذیری، پاسخگویی بلادرنگ، جداسازی سرویس‌ها و یکپارچگی داده‌ها.
- **تأثیر:** Kafka به استاندارد جهانی برای جریان داده تبدیل شد و معماری‌های مدرن مبتنی بر رویداد را شکل داد.

### نکات کلیدی برای مهندسان
1. **طراحی برای مقیاس‌پذیری:** هنگام طراحی سیستم‌های پیام‌رسانی، مقیاس‌پذیری افقی را از ابتدا در نظر بگیرید.
2. **استفاده از لاگ‌های پایدار:** ذخیره‌سازی داده‌ها برای بازپخش و بازیابی خطاها حیاتی است.
3. **مدیریت خوشه‌ها:** از ابزارهای خودکار مانند Cruise Control برای مدیریت خوشه‌های بزرگ استفاده کنید.
4. **ادغام با اکوسیستم:** سیستم‌های جریان داده باید با ابزارهای تحلیلی (مانند Hadoop) و پردازش بلادرنگ (مانند Samza) ادغام شوند.
5. **مشارکت در متن‌باز:** انتشار بهبودها به جامعه متن‌باز می‌تواند تأثیرات جهانی داشته باشد.

---

## منابع پیشنهادی برای مطالعه بیشتر
1. *Designing Data-Intensive Applications* نوشته مارتین کلپمن: کتابی جامع برای یادگیری سیستم‌های جریان داده.
2. *Kafka: The Definitive Guide* نوشته Neha Narkhede و همکاران: راهنمای کامل برای Kafka.
3. وبلاگ‌های مهندسی LinkedIn:
   - [Running Kafka at Scale](https://engineering.linkedin.com)[](https://engineering.linkedin.com/kafka/running-kafka-scale)
   - [How LinkedIn Customizes Apache Kafka](https://www.linkedin.com)[](https://www.linkedin.com/blog/engineering/open-source/apache-kafka-trillion-messages)
4. مستندات رسمی:
   - [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
   - [Apache Samza Documentation](https://samza.apache.org/)
5. دوره‌های آنلاین:
   - *Grokking the System Design Interview* در DesignGuru.io
   - *System Design Course* در Educative.io

---

این سند به‌طور جامع استفاده از Kafka در LinkedIn را توضیح داده و برای مهندسان علاقه‌مند به طراحی سیستم‌های مقیاس‌پذیر مناسب است. در صورت نیاز به جزئیات بیشتر یا مثال‌های دیگر، لطفاً اطلاع دهید!